{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f25846",
   "metadata": {},
   "source": [
    "# Symphony: CIFAR-10 Example\n",
    "\n",
    "**Visualizing a [DNIKit](https://betterwithdata.github.io/dnikit/) [Dataset Report](https://betterwithdata.github.io/dnikit/introspectors/data_introspection/dataset_report.html)**\n",
    "\n",
    "This is an example of visualizing the CIFAR-10 dataset with Symphony. Beyond the image samples themselves, we've used [DNIKit](https://betterwithdata.github.io/dnikit/) to compute some other statistics about the data. Symphony uses this data in the Familiarity and Duplicates widgets.\n",
    "\n",
    "In DNIKit, you can create a `DatasetReport` object, that has a `data` field, which is a pandas DataFrame table with metadata about each data sample like its familiarity, duplicates, overall summary, and dimensionality projection coordinates. Symphony can directly visualize this DataFrame.\n",
    "\n",
    "For this example, we'll load a precomputed analysis for the CIFAR-10 dataset that has been saved to disk as a pandas DataFrame. If you are interested in generating this DataFrame yourself (or for a different dataset or model), see [this DNIKit example](https://betterwithdata.github.io/dnikit/notebooks/data_introspection/dataset_report.ipynb). This Symphony example picks up at the end of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21f976",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Symphony in Jupyter Notebooks\n",
    "\n",
    "Let's use Symphony to explore this dataset in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d904ddac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 01:39:10.112196: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-29 01:39:10.131866: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-29 01:39:10.131884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-29 01:39:10.132546: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-29 01:39:10.136474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-29 01:39:10.502458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5882f87-25ef-4b37-8906-4f6098f57950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy     : 1.26.4\n",
      "scipy     : 1.14.1\n",
      "traitlets : 5.14.3\n",
      "tqdm      : 4.67.1\n",
      "easyimages: not installed\n",
      "tensorflow: 2.15.0\n",
      "keras     : 2.15.0\n",
      "dnikit    : not installed\n",
      "cffi      : 1.17.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from watermark import watermark\n",
    "print(watermark(packages=\"numpy,scipy,traitlets,tqdm,easyimages,tensorflow,keras,dnikit,cffi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df4b17",
   "metadata": {},
   "source": [
    "Let's first load and download the CIFAR-10 dataset. We'll save it to a folder named `cifar`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f60f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./cifar/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2d4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "class_to_name = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Concatenate the train and test into one array, as well as the train/test labels, and the class labels\n",
    "full_dataset = np.concatenate((x_train, x_test))\n",
    "dataset_labels = ['train']*len(x_train) + ['test']*len(x_test)\n",
    "class_labels = np.squeeze(np.concatenate((y_train, y_test)))\n",
    "\n",
    "# Helper function for file pathing\n",
    "def class_path(index, dataset_labels, class_labels):\n",
    "    return f\"{dataset_labels[index]}/{class_to_name[int(class_labels[index])]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee9d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through data and save images to `cifar` folder\n",
    "for idx in range(full_dataset.shape[0]):\n",
    "    base_path = os.path.join(data_path, class_path(idx, dataset_labels, class_labels))\n",
    "    Path(base_path).mkdir(exist_ok=True, parents=True)\n",
    "    filename = os.path.join(base_path, f\"image{idx}.png\")\n",
    "    # Write to disk after converting to BGR format, used by opencv\n",
    "    cv2.imwrite(filename, cv2.cvtColor(full_dataset[idx, ...], cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef06c2",
   "metadata": {},
   "source": [
    "Now that we have the images saved, we can load our precomputed analysis from DNIKit to visualize in Symphony. You can use Symphony to visualize CIFAR-10, and other datsets, directly. But some components require special metadata that we can use DNIKit's Dataset Report to generate automatically for us.\n",
    "\n",
    "We can also print out the DataFrame to see the types of metadata columns that are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e3021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('canvas_cifar_example.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d14f298-482f-4485-9210-1774086e47f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   id                                          60000 non-null  object \n",
      " 1   class                                       60000 non-null  object \n",
      " 2   dataset                                     60000 non-null  object \n",
      " 3   duplicates_conv_pw_13                       60000 non-null  int32  \n",
      " 4   projection_conv_pw_13_x                     60000 non-null  float32\n",
      " 5   projection_conv_pw_13_y                     60000 non-null  float32\n",
      " 6   familiarity_conv_pw_13                      60000 non-null  float64\n",
      " 7   splitFamiliarity_conv_pw_13_byAttr_class    60000 non-null  object \n",
      " 8   splitFamiliarity_conv_pw_13_byAttr_dataset  60000 non-null  object \n",
      "dtypes: float32(2), float64(1), int32(1), object(5)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a5104",
   "metadata": {},
   "source": [
    "To use Symphony, we'll import the main library and instantiate a Symphony object, passing the pandas DataFrame analysis and a file path to the dataset we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf60bd1-6e0f-46db-af5f-8331a8812786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "table = pa.Table.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fbfb432-4f0e-48b0-adeb-8fb3b3d303b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train/frog/image0.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.slice(0, 1)['id'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab1f2dff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas spect dict value is {'filesPath': '/files/./cifar/', 'dataType': 2, 'instancesPerPage': 40, 'showUnfilteredData': True, 'idColumn': 'id'}\n"
     ]
    }
   ],
   "source": [
    "import canvas_ux\n",
    "\n",
    "symph = canvas_ux.Canvas(df, files_path=str(data_path), notebook = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fedddc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To use the different Symphony widgets, you can import them indepdently. Let's first look at the Summary widget to see the overall distributions of our datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0eebc6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas spect dict value is {'width': 'XXL', 'height': 'M', 'page': 'Summary', 'name': 'CanvasSummary', 'description': 'A Canvas component that visualizes an overview of a dataset', 'summaryElements': []}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c006101ba5314995b68fcfbe37332f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(CanvasSummary(layout=Layout(overflow='unset', width='100%'), widget_spec={'width': 'XXL', 'heig…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from canvas_summary import CanvasSummary\n",
    "\n",
    "symph.widget(CanvasSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d3ad1",
   "metadata": {},
   "source": [
    "Instead of a summary, if we want to browse through the data we can use the List widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0cc1ce2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/satish/Development/workspace/projects/deepview_dev/notebooks/data_introspection\n",
      "Canvas spect dict value is {'width': 'XXL', 'height': 'M', 'page': 'List', 'name': 'CanvasList', 'description': 'A Canvas component that displays a view of data instances'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8538de0ae534be5b526678aef54b25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(CanvasList(layout=Layout(overflow='unset', width='100%'), widget_spec={'width': 'XXL', 'height'…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from canvas_list import CanvasList\n",
    "\n",
    "symph.widget(CanvasList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2877bd-43fa-4176-a9d0-ab1ae0f05470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d7ab972",
   "metadata": {},
   "source": [
    "It's common to use dimensionality reduction techniques to summarize and find patterns in ML dataset. DNIKit already ran a reduction, and saves it when running a DataSet Report. We can use the Scatterplot widget to visualize this embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f188e4f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da78e2be6a18438e85a7be5df0d0389b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(CanvasScatterplot(canvas_spec={'filesPath': '/files/./cifar/', 'dataType': 2, 'instancesPerPage…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from canvas_scatterplot import CanvasScatterplot\n",
    "\n",
    "symph.widget(CanvasScatterplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a918cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some datasets can contain duplicates: data instances that are the same or very similar to others. These can be hard to find, and become espeically problematic if the same data instance is in the training and testing splits. We can answer these questions using the Duplicates widget.\n",
    "\n",
    "Hint: Take a look at the `automobile` class, where there are duplicates across train and test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b99eb410",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas spect dict value is {'width': 'XXL', 'height': 'M', 'page': 'Duplicates', 'name': 'CanvasDuplicates', 'description': 'A Canvas component for inspecting potential duplicates in a dataset'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a1272588e94eb8aa71407aabfb5f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(CanvasDuplicates(layout=Layout(overflow='unset', width='100%'), widget_spec={'width': 'XXL', 'h…"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from canvas_duplicates import CanvasDuplicates\n",
    "\n",
    "symph.widget(CanvasDuplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7579f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lastly, we can use advanced ML metrics and the Familiarity widget to find the most and least representative data instances from a given datset, which can help identify model biases and annotation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "723aaa6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas spect dict value is {'width': 'XXL', 'height': 'M', 'page': 'Familiarity', 'name': 'CanvasFamiliarity', 'description': 'A Canvas component to find outliers and common instances in a dataset'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47536a124834d77a32f94fb790f0617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(CanvasFamiliarity(layout=Layout(overflow='unset', width='100%'), widget_spec={'width': 'XXL', '…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from canvas_familiarity import CanvasFamiliarity\n",
    "\n",
    "symph.widget(CanvasFamiliarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe645eb9",
   "metadata": {},
   "source": [
    "## Symphony as a Standalone Export\n",
    "\n",
    "Symphony can also be exported as a standalone static export to be shared with others or hosted. To explore this example in a web browser, you can export the report to local folder.\n",
    "\n",
    "If you only want to visualize locally without sharing the data, you can specify Symphony to handle the paths for a local standlone visualization by setting ``symlink_files`` to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "symph.export('./symphony_report', name=\"Symphony CIFAR-10 Example\", symlink_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710755c2",
   "metadata": {},
   "source": [
    "You can now serve the dataset report. For example, from the `symphony_export` folder, run a simple server from the command line:\n",
    "\n",
    "```bash\n",
    "python -m http.server\n",
    "```\n",
    "\n",
    "And navigate to http://localhost:8000/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faff5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1638994625349,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "betterwithdata",
   "language": "python",
   "name": "betterwithdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
